import logging
import sys
import time
import os
import tempfile
from typing import List, Dict
import pandas as pd

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

from gcs_uploader import upload_to_gcs

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)

# âœ… ìš”ì†Œ ë¡œë”© ì—¬ë¶€ íŒë‹¨
def elements_loaded(driver, selector: str) -> bool:
    try:
        elements = driver.find_elements(By.CSS_SELECTOR, selector)
        return len(elements) > 0 and any(e.text.strip() for e in elements)
    except Exception as e:
        logging.warning(f"âŒ elements_loaded() ë‚´ë¶€ ì˜¤ë¥˜: {e}")
        return False

# âœ… ê³µí†µ ëŒ€ê¸° í•¨ìˆ˜
def wait_for_elements(driver, selector: str, timeout: int = 15, wait_time: float = 3) -> bool:
    start = time.time()
    try:
        WebDriverWait(driver, timeout).until(lambda d: elements_loaded(d, selector))
        time.sleep(wait_time)
        return True
    except TimeoutException:
        logging.warning(f"âš ï¸ ìš”ì†Œ ë¡œë”© ì‹¤íŒ¨: {selector}")
        return False

# âœ… ë¦¬ë·° ì •ë ¬ ì˜µì…˜ í´ë¦­ í•¨ìˆ˜
def click_sort_option(driver, text: str = "ìµœì‹ ìˆœ"):
    try:
        sort_button = WebDriverWait(driver, 5).until(
            EC.element_to_be_clickable((By.XPATH, f'//ul[contains(@class, "KQTUBC8Cw8")]//a[text()="{text}"]'))
        )
        driver.execute_script("arguments[0].click();", sort_button)
        # logging.info(f"âœ… ë¦¬ë·° ì •ë ¬ '{text}' í´ë¦­ ì™„ë£Œ")
        time.sleep(2)
    except Exception as e:
        logging.warning(f"âš ï¸ ë¦¬ë·° ì •ë ¬ '{text}' í´ë¦­ ì‹¤íŒ¨: {e}")

# âœ… ë¦¬ë·° íŒŒì‹±
def parse_review_element(element) -> Dict:
    def safe_find(selector, by=By.CSS_SELECTOR, many=False):
        try:
            return (element.find_elements if many else element.find_element)(by, selector)
        except:
            return [] if many else None

    review_id = element.get_attribute("data-shp-contents-id")
    username = safe_find("strong._2L3vDiadT9")
    username = username.text.strip() if username else None

    date_spans = safe_find("span._2L3vDiadT9", many=True)
    created_at = next((s.text.strip() for s in date_spans if "." in s.text), None)

    rating = safe_find("em._15NU42F3kT")
    rating = rating.text.strip() if rating else None

    content = None
    try:
        content_element = element.find_element(By.CSS_SELECTOR, "div._1kMfD5ErZ6 > span._2L3vDiadT9")
        content = content_element.text.strip()
    except:
        try:
            fallback = element.find_element(By.CSS_SELECTOR, "div._3z6gI4oI6l")
            content = fallback.text.strip()
        except:
            content = None

    option = safe_find("div._2FXNMst_ak")
    option = option.text.strip() if option else None

    return {
        "review_id": review_id,
        "username": username,
        "created_at": created_at,
        "rating": rating,
        "content": content,
        "option": option
    }

# âœ… í•œ í˜ì´ì§€ ë¦¬ë·° ì¶”ì¶œ
def extract_reviews_from_page(driver) -> List[Dict]:
    logging.info("â³ ë¦¬ë·° ìš”ì†Œ ë¡œë”© ëŒ€ê¸° ì¤‘...")
    reviews = []

    if not wait_for_elements(driver, "li.BnwL_cs1av", timeout=15, wait_time=1.5):
        logging.warning("âš ï¸ ë¦¬ë·° ìš”ì†Œ ë¡œë”© ì‹¤íŒ¨ â†’ í˜ì´ì§€ ê±´ë„ˆëœ€")
        return []

    review_elements = driver.find_elements(By.CSS_SELECTOR, "li.BnwL_cs1av")

    for element in review_elements:
        try:
            more_span = element.find_elements(By.CSS_SELECTOR, "span._3R1ftMxgoY")
            if more_span:
                driver.execute_script("arguments[0].click();", more_span[0])
                time.sleep(0.1)

            review = parse_review_element(element)
            if review.get("content"):
                reviews.append(review)
        except Exception as e:
            logging.warning(f"âŒ ë¦¬ë·° íŒŒì‹± ì‹¤íŒ¨: {e}")
            continue

    return reviews

# âœ… ì „ì²´ ë¦¬ë·° ìˆ˜ì§‘ íë¦„
def collect_and_save(product_id: str, category_name: str, product_url: str,
                     bucket_name: str, timestamp: str, max_reviews: int = 200):
    logging.info(f"ğŸ” ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘: [{category_name}] {product_id}")
    reviews = []
    MAX_PAGES = 20

    for page in range(1, MAX_PAGES + 1):
        if len(reviews) >= max_reviews:
            logging.info("âœ… ìµœëŒ€ ë¦¬ë·° ìˆ˜ ë„ë‹¬ â†’ ì¢…ë£Œ")
            break

        logging.info(f"ğŸ” [í˜ì´ì§€ {page}] ìˆ˜ì§‘ì„ ìœ„í•œ ë“œë¼ì´ë²„ ì´ˆê¸°í™”")

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--disable-extensions")
        options.add_argument("--disable-popup-blocking")
        options.add_argument("--blink-settings=imagesEnabled=false")
        options.add_argument("--disable-background-networking")
        options.add_argument("--disable-sync")
        options.add_argument("--disable-translate")
        options.add_argument("--disable-features=NetworkService")
        options.add_argument("--no-first-run")

        driver = webdriver.Chrome(options=options)

        try:
            driver.get(product_url)
            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            time.sleep(2)

            # ë¦¬ë·° íƒ­ í´ë¦­
            try:
                review_tab = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, '//a[contains(text(), "ë¦¬ë·°")]'))
                )
                try:
                    review_tab.click()
                except:
                    driver.execute_script("arguments[0].click();", review_tab)
                time.sleep(2)

                # âœ… ì •ë ¬: ìµœì‹ ìˆœ í´ë¦­
                click_sort_option(driver, text="ìµœì‹ ìˆœ")

            except TimeoutException:
                logging.warning(f"âŒ ë¦¬ë·° íƒ­ í´ë¦­ ì‹¤íŒ¨: {product_id} â†’ í˜ì´ì§€ {page} ê±´ë„ˆëœ€")
                continue

            # "ë‹¤ìŒ" ë²„íŠ¼ page-1ë²ˆ í´ë¦­
            for _ in range(1, page):
                try:
                    next_btn = WebDriverWait(driver, 5).until(
                        EC.element_to_be_clickable((By.XPATH, '//a[text()="ë‹¤ìŒ"]'))
                    )
                    driver.execute_script("arguments[0].click();", next_btn)
                    time.sleep(1.5)
                except Exception as e:
                    logging.warning(f"âš ï¸ í˜ì´ì§€ {page} ì´ë™ ì¤‘ 'ë‹¤ìŒ' ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {e}")
                    break

            logging.info(f"ğŸ” í˜ì´ì§€ {page} ë¦¬ë·° ì¶”ì¶œ ì‹œì‘")
            new_reviews = extract_reviews_from_page(driver)

            if not new_reviews:
                logging.warning(f"âš ï¸ í˜ì´ì§€ {page}ì—ì„œ ë¦¬ë·° ì—†ìŒ ë˜ëŠ” ë¡œë”© ì‹¤íŒ¨ â†’ ê±´ë„ˆëœ€")
                continue

            reviews.extend(new_reviews)
            #logging.info(f"ğŸ“„ í˜ì´ì§€ {page}ì—ì„œ {len(new_reviews)}ê°œ ë¦¬ë·° ì¶”ì¶œë¨")
            logging.info(f"ğŸ” ì´ ëˆ„ì  ë¦¬ë·° ìˆ˜: {len(reviews)}")

        except Exception as e:
            logging.error(f"âŒ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            continue
        finally:
            driver.quit()

    save_reviews(reviews, bucket_name, category_name, product_id, timestamp, max_reviews)

# âœ… ê²°ê³¼ ì €ì¥
def save_reviews(reviews: List[Dict], bucket_name: str, category_name: str,
                 product_id: str, timestamp: str, max_reviews: int):
    if not reviews:
        logging.warning(f"âš ï¸ ìˆ˜ì§‘ëœ ë¦¬ë·° ì—†ìŒ: {product_id}")
        return

    df = pd.DataFrame(reviews[:max_reviews])
    with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", encoding="utf-8-sig", delete=False) as tmp:
        df.to_csv(tmp.name, index=False)
        tmp_path = tmp.name

    blob_path = f"raw-data/naver/{category_name}/reviews/{product_id}/{timestamp}_reviews.csv"
    upload_to_gcs(bucket_name, content=tmp_path, blob_path=blob_path, content_type="text/csv", from_bytes=False)
    logging.info(f"ğŸ“¤ ì—…ë¡œë“œ ì™„ë£Œ: gs://{bucket_name}/{blob_path}")
    os.remove(tmp_path)
